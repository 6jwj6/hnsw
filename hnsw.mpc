from Compiler.library import *
from Compiler.types import *
from Compiler.oram import *
from Programs.Source.HeapQ import MinHeapQ,MaxHeapQ
import time
from Compiler.mpc_math import *
# --- 全局常量和变量 ---
MINX = -1000
MAXX = 1000

D = 4  # 向量维度
M = 5  # 每个节点的最大连接数 (除第0层外)
MMAX0 = 2 * M  # 第0层的最大连接数
MMAX = M
N = 10  # 数据点数量
EF_CONSTRUCTION = 5  # 构建索引时的搜索范围大小
K = 3  # K-NN搜索中的K值
NlgN = N * (int)(math.log2(N))
# 数据和图结构
node =  OptimalORAM(size = N + 1, value_length = D)
edge = OptimalORAM(size = N + 1, value_length = MMAX0 + 5)  # 邻接表, edge[0] 作为占位符
edgelen = OptimalORAM(size = N + 1)
ite = OptimalORAM(size = NlgN)   # 索引到节点ID的映射, ite[0] 作为占位符

# HNSW 算法状态
L = 0  # 当前最高层数
EP = 1  # 入口点 (entry point) 的索引
nodecnt = 0  # 图中节点的总数 (跨所有层)
ML = 1 / math.log(M)

def tryoram():
    x = OptimalORAM(size = 32, value_length = 4)
    x.access(sint(1), (2,3,4,2), True)
    va = x[1]
    vv = va[2] # tuple [0,3]
    print_ln('x[1][2] = %s',vv.reveal())
    x.delete(1)
    print_ln('%s', x[1][2].reveal())

def tryheapq():
    Q = MaxHeapQ(max_size=100)

    for i in range(10):
        op = sint.get_input_from(0)
        x = sint.get_input_from(0)
        x = x + 100
        pos = i + 130
        Q.update(pos, x, op==1)
        entry_Pop = Q.pop(op==0)
        entry_Top = Q.top(op==2)
        
        @if_((op==1).reveal())
        def _():
            print_ln('%s inserted at %s...', x.reveal(), pos)
            print_ln('size = %s',Q.size.reveal())

        @if_((op==0).reveal())
        def _():
            print_ln('%s poped...', entry_Pop[0].reveal())
            print_ln('size = %s',Q.size.reveal())

        @if_((op==2).reveal())
        def _():
            print_ln('%s is the top...', entry_Top[0].reveal())
            print_ln('size = %s',Q.size.reveal())

        over_size = Q.size > 3
        @if_(over_size.reveal())
        def _():
            ee = Q.pop(over_size)
            print_ln('size > 3, %s poped...', ee[0].reveal())
            print_ln('size = %s',Q.size.reveal())

    print_ln('-'*50+'END'+'-'*50)

def test():
    a = OptimalORAM(size = 101, value_length = MMAX0+10)
    a[1] = (3,4,5)
    a[a[1][2]] = (3,3,4,5)
    print_ln('aaa = %s', a[5][2].reveal())
    for i in range(10):
        tmp = sint.Array(100)
        tmp.input_from(1)
        print_ln('%s',type(tmp))
        print_ln('%s',tmp.reveal_list())
        # for _ in range(100):
        #     print_ln('%s', tmp[_].reveal())
        # a.access(i,[*tmp],True)
        # a.access(i, tuplify([*tmp]), True)
        # a[i] = tuplify([*tmp])
        a[i] = [*tmp]
        # print_ln('%s',[a[i][j].reveal() for j in range(D)])
        print_ln('a[i][3] = %s',a[i][3].reveal())
        a.delete(i)
        print_ln('%s', a[i][2].reveal())

def distance_query_to_node(q_idx, node_idx):
    """计算一个查询点和一个主数据集节点之间的距离"""
    vec1 = querynode[q_idx]
    vec2 = node[node_idx]
    res = sint(0)
    for i in range(D):
        res = res + (vec1[i]-vec2[i]) * (vec1[i]-vec2[i])
    return res

def distance_node_to_node(idx1, idx2):
    """计算主数据集中两个节点之间的距离"""
    vec1 = node[idx1]
    vec2 = node[idx2]
    res = sint(0)
    for i in range(D):
        res = res + (vec1[i]-vec2[i]) * (vec1[i]-vec2[i])
    return res

def nxt(W):
    return [i + 1 for i in W]

def search_layer(q_idx, ep, ef, lc):
    return

def search_layer_for_query(q_idx, ep, ef, lc):
    return

def select_neighbors_heuristic(q_idx, C, M_conn, lc, extend_candidates=False, keep_pruned_connections=True):
    return

def insert(q_idx, M_param, Mmax_param, efConstruction_param, mL_param):
    global L, EP, nodecnt
    current_ep = [EP] if nodecnt != 0 else []
    l = math.floor(-math.log(random.uniform(0.0, 1.0)) * mL_param)
    if l > L:
        EP = nodecnt + 1
        for _ in range(l, L, -1):
            nodecnt += 1
            # ite.append(q_idx)
            ite[nodecnt] = q_idx
    for lc in range(L, l, -1):
        W = search_layer(q_idx, current_ep, 1, lc)
        if not W: break
        assert len(W) == 1
        current_ep = nxt(W)
    for lc in range(min(L, l), -1, -1):
        m_max_lc = MMAX0 if lc == 0 else Mmax_param
        nodecnt += 1
        # ite.append(q_idx)
        ite[nodecnt] = q_idx
        W = search_layer(q_idx, current_ep, efConstruction_param, lc)
        if not W:
            # edge.append([])
            continue
        neighbors = select_neighbors_heuristic(q_idx, W, M_param, lc)
        # edge.append(neighbors)
        '''这里不知道个数，需要再处理'''
        edge[nodecnt] = neighbors 
        new_node_graph_idx = nodecnt
        for e_node_idx in neighbors:
            edge[e_node_idx].append(new_node_graph_idx)
            if len(edge[e_node_idx]) > m_max_lc:
                e_conn = edge[e_node_idx]
                e_new_conn = select_neighbors_heuristic(ite[e_node_idx], e_conn, m_max_lc, lc)
                edge[e_node_idx] = e_new_conn
        current_ep = nxt(W)
    if l > L:
        L = l

def k_nn_search(q_idx, k_param, ef_param):
    return

# --- 初始化和主程序 ---
def init():
    """从文件加载数据"""
    print_ln("开始读取数据...")
    tmp = sint.Array(D)
    for i in range(1, N + 1):
        tmp.input_from(1)
        node[i] = [*tmp]
    print_ln("完成读取 data.txt")
    
    # 打印前3个节点以供验证 (这部分代码保持不变)
    if N >= 3:
        for i in range(1, 4):
            print_ln("节点 %s: %s", i, [node[i][j].reveal() for j in range(D)])

def bruteforce_for_query(q_idx):
    """暴力搜索查询点 q_idx 的 K 个最近邻"""
    start_time = time.time()
    # Q = MaxHeapQ(max_size = K + 2)
    for i in range(1, N + 1):
        dist = distance_query_to_node(q_idx, i)
        Q.update(i, dist)
        Q.pop(Q.size > K)
    ret = [Q.pop()[1].reveal() for _ in range(K)]
    # ret.sort()
    end_time = time.time()
    duration_ms = (end_time - start_time) * 1000
    print_ln("\n暴力搜索结果:")
    print_ln('序号: %s',ret)
    # for r_idx in ret:
    #     dist = distance_query_to_node(q_idx, r_idx)
    #     print_ln("%s || %s", [node[r_idx][_].reveal() for _ in range(D)], dist.reveal())
    print_ln("查询耗时: %s ms", duration_ms)
    return ret

'''-------------------主程序-----------------------------'''
print_ln('-'*50+'RESULT'+'-'*50)
# test()

print_ln("*"*50)
print_ln("N (数据点数): %s", N)
print_ln("D (维度): %s", D)
print_ln("M (最大连接数): %s", M)
print_ln("mL (层级因子): %s", ML)
print_ln("K (近邻数): %s", K)
print_ln("efConstruction: %s", EF_CONSTRUCTION)
print_ln("*"*50)
init()

start_insert = time.time()
for i in range(1, N + 1):
    insert(i, M, MMAX, EF_CONSTRUCTION, ML)
    if i * 100 % N  == 0:
        print_ln("已插入节点数 = %s / %s", i, N)
end_insert = time.time()
duration_insert = end_insert - start_insert 
print_ln("\nHNSW 图构建完成")


nq = 21
querynode = [] # 确保查询列表是空的
for i in range(nq):
    val = ((i - (nq - 1) / 2) * ((MAXX - MINX) / (nq - 1)))
    querynode.append([sint(int(val))] * D)

Q = MaxHeapQ(max_size = K + 2)
ave_recall = 0.0
for q_idx in range(9,11):
    # 现在的 q_idx 就是 querynode 列表的索引 (0, 1, 2...)

    print_ln("\n--------------------------------")
    print_ln("当前查询点 (索引 %s) 为 (%s)",q_idx,
                [querynode[q_idx][_].reveal() for _ in range(D)])
    
    # print_ln("\nq 的 K-ANN 搜索结果:")
    # start_query = time.time()
    # # 调用查询专用函数 k_nn_search，并传递查询索引
    # knn_res = k_nn_search(q_idx, K, EF_CONSTRUCTION)
    # end_query = time.time()
    # duration_query_ms = (end_query - start_query) * 1000

    # print_ln("序号: %s", knn_res)
    # for res_idx in knn_res:
    #     dist = distance_query_to_node(q_idx, res_idx)
    #     print_ln("%s || %s", res_idx, dist)
    # print_ln("查询耗时: %s ms", duration_query_ms)

    # 调用查询专用的暴力搜索函数    
    brt_res = bruteforce_for_query(q_idx)
    
    # brt_set = set(brt_res)
    # ccnt = sum(1 for res_idx in knn_res if res_idx in brt_set)
    # recall = ccnt / K
    # ave_recall += recall
    # print(f"召回率: {recall:.4f}", file=sys.stderr)
    # print("-------------------------------------\n", file=sys.stderr)
# # --- 修改结束 (6/6) ---
    
# print(f"平均召回率: {ave_recall / nq:.4f}", file=sys.stderr)
# print(f"插入耗时: {duration_insert:.4f} seconds", file=sys.stderr)

print_ln('-'*50+'END'+'-'*50)